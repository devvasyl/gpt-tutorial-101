---
sidebar_position: 5
---

# 5.1.5. 更多高阶技巧

## ReAct

谷歌团队在 2022.10 发表了一个研究，它们引入了一个框架，其中 LLMs 以交错的方式生成推理轨迹和任务特定的操作。生成推理轨迹使模型能够诱导、跟踪和更新行动计划，甚至处理异常情况。操作步骤允许与外部源（如知识库或环境）进行接口和信息收集。

爆火的 Auto-GPT 便是参考了当前的框架，从而表现的非常出色，可以自行制定每一步计划。

其名字的来源便是框架的解释：__ReAct = Reasoning（协同推理） + Acting（行动）__

![](../../assets/6.1麻瓜读论文/ReAct/Untitled%201.png)

相关论文解读可以见下文参考阅读中的链接，因为整个方法操作起来比较简单，论文中其实没有太多提及具体的操作步骤，更多地在介绍与 CoT、Fine Tuning 等方式的效果对比。

作者在这里简要介绍一下这个框架的思想，其实从上面这张图就能看出来，在 Prompt 的时候包含几个元素：

1. **思考（Thought）：推理过程的文字展示**，我要干什么，或者说我想要 LLM 帮我做什么，以及为了达成这件事情所需要的前置条件是什么；
2. **行动（Act）：生成与外部交互的指令**，确定这一步要做什么之后所生成的对应行为指令文字，比如遇到了 LLM 没有预设的知识，要进行搜索；
3. **观察（Obs）：从外部获取执行指令得到的结果**，相当于拿到当前这一步的行为的结果，准备进行下一步，比如如果是搜索的话，这里就会是搜索结果；